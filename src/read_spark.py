from pyspark.sql import SparkSession

# 1. Crear SparkSession
spark = SparkSession.builder \
    .appName("Read_VacaMuerta") \
    .getOrCreate()

# 2. Leer Parquet procesado
df = spark.read.parquet("/home/eze/vaca-muerta-pipeline/data/processed/fracturas_spark")

# 3. Mostrar primeras filas
print("游녤 Primeras filas del dataset procesado:")
df.show(5)

# 4. Conteo por a침o y mes
print("游녤 Conteo de fracturas por a침o y mes:")
df.groupBy("anio", "mes").count().show()

# 5. Esquema final
print("游녤 Esquema final del DataFrame:")
df.printSchema()

# 6. Estadisticas Descriptivas
print("Estadisticas descriptivas:")
df.describe(["arena_total_tn", "agua_inyectada_m3", "presion_maxima_psi"]).show()

# 7. Top 5 yacimientos
print("Top 5 yacimientos con mas fracturas:")
df.groupBy("yacimiento").count().orderBy("count", ascending=False).show(5)

# 8. Evolucion temporal (solo por a침o)
print("Conteo de fracturas por a침o")
df.groupBy("anio").count().orderBy("anio").show()